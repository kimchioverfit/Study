# Categorical Cross Entropy 


$$
\text{CCE}(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{i=1}^{C} y_i \cdot \log(\hat{y}_i)
$$

예를 들어, 


정답이 y = [0,1,0] 인 경우가 있다고 칠 때, 
$$
(\hat{y}) = [0.1,0.85,0.05] 
$$
의 예측값이 나왔다고 하자. 

손실은 정답값에만 영향을 받는다

$$
Loss = -log(0.85) ≈ 0.1625
$$

(참고 사항 : 항상 정답이 정수 원소는 아님. 헷갈리는 경우를 답지에 넣을 때, y = [0.2, 0.7, 0.1] 이런 식으로 소수 값을 넣기도 함.)




